{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Using LSTMs to Classify the 20 Newsgroups Data Set\n",
    "The 20 Newsgroups data set is a well known classification problem. The goal is to classify which newsgroup a particular post came from.  The 20 possible groups are:\n",
    "\n",
    "`comp.graphics\n",
    "comp.os.ms-windows.misc\n",
    "comp.sys.ibm.pc.hardware\n",
    "comp.sys.mac.hardware\n",
    "comp.windows.x\trec.autos\n",
    "rec.motorcycles\n",
    "rec.sport.baseball\n",
    "rec.sport.hockey\t\n",
    "sci.crypt\n",
    "sci.electronics\n",
    "sci.med\n",
    "sci.space\n",
    "misc.forsale\t\n",
    "talk.politics.misc\n",
    "talk.politics.guns\n",
    "talk.politics.mideast\t\n",
    "talk.religion.misc\n",
    "alt.atheism\n",
    "soc.religion.christian`\n",
    "\n",
    "As you can see, some pairs of groups may be quite similar while others are very different.\n",
    "\n",
    "The data is given as a designated training set of size 11314 and test set of size 7532.  The 20 categories are represented in roughly equal proportions, so the baseline accuracy is around 5%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, review the code below.  This will walk you through the basics of loading in the 20 newsgroups data, loading in the GloVe data, building the word embedding matrix, and building the LSTM model.\n",
    "\n",
    "After we build the first LSTM model, it will be your turn to build one and play with the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "import keras\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "seq_length = 30  # How long to make our word sequences\n",
    "batch_size = 32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the 20 newsgroups data - there is already a designated \"train\" and \"test\" set\n",
    "\n",
    "newsgroup_train = fetch_20newsgroups(subset='train')\n",
    "newsgroup_test = fetch_20newsgroups(subset='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 7532)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroup_train.data), len(newsgroup_test.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the Glove pre-trained word vectors.  If you haven't already, please download them using this link:\n",
    "(NOTE: this will start downloading an 822MB file)\n",
    "\n",
    "http://nlp.stanford.edu/data/glove.6B.zip\n",
    "\n",
    "Then unzip the file and fill your local path to the file in the code cell below.\n",
    "\n",
    "We will use the file `glove.6B.100d.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(newsgroup_train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just look at a word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_train = tokenizer.texts_to_sequences(newsgroup_train.data)\n",
    "sequences_test = tokenizer.texts_to_sequences(newsgroup_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 134142 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(sequences_train, maxlen=seq_length)\n",
    "x_test = pad_sequences(sequences_test, maxlen=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(np.asarray(newsgroup_train.target))\n",
    "y_test = keras.utils.to_categorical(np.asarray(newsgroup_test.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "f = open('C:/Users/lucas/Documents/GitHub/glove.6B/glove.6B.100d.txt', encoding='utf-8')\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30817  ,  0.30938  ,  0.52803  , -0.92543  , -0.73671  ,\n",
       "        0.63475  ,  0.44197  ,  0.10262  , -0.09142  , -0.56607  ,\n",
       "       -0.5327   ,  0.2013   ,  0.7704   , -0.13983  ,  0.13727  ,\n",
       "        1.1128   ,  0.89301  , -0.17869  , -0.0019722,  0.57289  ,\n",
       "        0.59479  ,  0.50428  , -0.28991  , -1.3491   ,  0.42756  ,\n",
       "        1.2748   , -1.1613   , -0.41084  ,  0.042804 ,  0.54866  ,\n",
       "        0.18897  ,  0.3759   ,  0.58035  ,  0.66975  ,  0.81156  ,\n",
       "        0.93864  , -0.51005  , -0.070079 ,  0.82819  , -0.35346  ,\n",
       "        0.21086  , -0.24412  , -0.16554  , -0.78358  , -0.48482  ,\n",
       "        0.38968  , -0.86356  , -0.016391 ,  0.31984  , -0.49246  ,\n",
       "       -0.069363 ,  0.018869 , -0.098286 ,  1.3126   , -0.12116  ,\n",
       "       -1.2399   , -0.091429 ,  0.35294  ,  0.64645  ,  0.089642 ,\n",
       "        0.70294  ,  1.1244   ,  0.38639  ,  0.52084  ,  0.98787  ,\n",
       "        0.79952  , -0.34625  ,  0.14095  ,  0.80167  ,  0.20987  ,\n",
       "       -0.86007  , -0.15308  ,  0.074523 ,  0.40816  ,  0.019208 ,\n",
       "        0.51587  , -0.34428  , -0.24525  , -0.77984  ,  0.27425  ,\n",
       "        0.22418  ,  0.20164  ,  0.017431 , -0.014697 , -1.0235   ,\n",
       "       -0.39695  , -0.0056188,  0.30569  ,  0.31748  ,  0.021404 ,\n",
       "        0.11837  , -0.11319  ,  0.42456  ,  0.53405  , -0.16717  ,\n",
       "       -0.27185  , -0.6255   ,  0.12883  ,  0.62529  , -0.52086  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_vec = embeddings_index['dog']\n",
    "dog_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This creates a matrix where the $i$th row gives the word embedding for the word represented by integer $i$.\n",
    "## Essentially, these will be the \"weights\" for the Embedding Layer\n",
    "## Rather than learning the weights, we will use these ones and \"freeze\" the layer\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 100))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134143, 100)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Layer\n",
    "`keras.layers.recurrent.LSTM(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0)`\n",
    "\n",
    "- Similar in structure to the `SimpleRNN` layer\n",
    "- `units` defines the dimension of the recurrent state\n",
    "- `recurrent_...` refers the recurrent state aspects of the LSTM\n",
    "- `kernel_...` refers to the transformations done on the input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 30, 100)           13414300  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 30)                15720     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                620       \n",
      "=================================================================\n",
      "Total params: 13,430,640\n",
      "Trainable params: 16,340\n",
      "Non-trainable params: 13,414,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "word_dimension = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1, \n",
    "                    word_dimension, \n",
    "                    weights=[embedding_matrix], \n",
    "                    input_length=seq_length, \n",
    "                    trainable=False))\n",
    "\n",
    "model.add(LSTM(30, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(20, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(lr=0.002)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=rmsprop, \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "354/354 [==============================] - 7s 21ms/step - loss: 2.7262 - accuracy: 0.1577 - val_loss: 2.4701 - val_accuracy: 0.2257\n",
      "Epoch 2/20\n",
      "354/354 [==============================] - 8s 23ms/step - loss: 2.2822 - accuracy: 0.2882 - val_loss: 2.1603 - val_accuracy: 0.3201\n",
      "Epoch 3/20\n",
      "354/354 [==============================] - 10s 27ms/step - loss: 2.0549 - accuracy: 0.3577 - val_loss: 2.0599 - val_accuracy: 0.3521\n",
      "Epoch 4/20\n",
      "354/354 [==============================] - 9s 26ms/step - loss: 1.9154 - accuracy: 0.4084 - val_loss: 1.9449 - val_accuracy: 0.3898\n",
      "Epoch 5/20\n",
      "354/354 [==============================] - 9s 25ms/step - loss: 1.8205 - accuracy: 0.4354 - val_loss: 2.0093 - val_accuracy: 0.3805\n",
      "Epoch 6/20\n",
      "354/354 [==============================] - 9s 26ms/step - loss: 1.7400 - accuracy: 0.4639 - val_loss: 1.8826 - val_accuracy: 0.4218\n",
      "Epoch 7/20\n",
      "354/354 [==============================] - 9s 26ms/step - loss: 1.6800 - accuracy: 0.4827 - val_loss: 1.8597 - val_accuracy: 0.4283\n",
      "Epoch 8/20\n",
      "354/354 [==============================] - 9s 26ms/step - loss: 1.6400 - accuracy: 0.4917 - val_loss: 1.8246 - val_accuracy: 0.4371\n",
      "Epoch 9/20\n",
      "354/354 [==============================] - 9s 26ms/step - loss: 1.5924 - accuracy: 0.5058 - val_loss: 1.8073 - val_accuracy: 0.4438\n",
      "Epoch 10/20\n",
      "354/354 [==============================] - 9s 26ms/step - loss: 1.5575 - accuracy: 0.5171 - val_loss: 1.8007 - val_accuracy: 0.4518\n",
      "Epoch 11/20\n",
      "354/354 [==============================] - 9s 26ms/step - loss: 1.5263 - accuracy: 0.5271 - val_loss: 1.7794 - val_accuracy: 0.4576\n",
      "Epoch 12/20\n",
      "354/354 [==============================] - 10s 27ms/step - loss: 1.5000 - accuracy: 0.5405 - val_loss: 1.7976 - val_accuracy: 0.4558\n",
      "Epoch 13/20\n",
      "354/354 [==============================] - 9s 26ms/step - loss: 1.4736 - accuracy: 0.5455 - val_loss: 1.7966 - val_accuracy: 0.4565\n",
      "Epoch 14/20\n",
      "354/354 [==============================] - 10s 27ms/step - loss: 1.4648 - accuracy: 0.5427 - val_loss: 1.7920 - val_accuracy: 0.4558\n",
      "Epoch 15/20\n",
      "354/354 [==============================] - 10s 29ms/step - loss: 1.4444 - accuracy: 0.5489 - val_loss: 1.7923 - val_accuracy: 0.4640\n",
      "Epoch 16/20\n",
      "354/354 [==============================] - 9s 26ms/step - loss: 1.4324 - accuracy: 0.5559 - val_loss: 1.8139 - val_accuracy: 0.4566\n",
      "Epoch 17/20\n",
      "354/354 [==============================] - 10s 28ms/step - loss: 1.4090 - accuracy: 0.5615 - val_loss: 1.8101 - val_accuracy: 0.4651\n",
      "Epoch 18/20\n",
      "354/354 [==============================] - 9s 27ms/step - loss: 1.3901 - accuracy: 0.5642 - val_loss: 1.7949 - val_accuracy: 0.4687\n",
      "Epoch 19/20\n",
      "354/354 [==============================] - 10s 28ms/step - loss: 1.3815 - accuracy: 0.5659 - val_loss: 1.8023 - val_accuracy: 0.4684\n",
      "Epoch 20/20\n",
      "354/354 [==============================] - 10s 28ms/step - loss: 1.3713 - accuracy: 0.5723 - val_loss: 1.7922 - val_accuracy: 0.4740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x238ddb855c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "          batch_size=batch_size, \n",
    "          epochs=20, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise\n",
    "### Your Turn\n",
    "- Build a neural network with a SimpleRNN instead of an LSTM (with other dimensions and parameters the same). How does the performance compare?\n",
    "- Use the LSTM above without the pretrained word vectors (randomly initialize the weights and have them be learned during the training process).  How does the performance compare?\n",
    "- Try different sequence lengths, and dimensions for the hidden state of the LSTM.  Can you improve the model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 100)           13414300  \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 50)                7550      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                1020      \n",
      "=================================================================\n",
      "Total params: 13,422,870\n",
      "Trainable params: 8,570\n",
      "Non-trainable params: 13,414,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_hidden_dim = 50\n",
    "\n",
    "model_2 = Sequential()\n",
    "model_2.add(Embedding(len(word_index) + 1, \n",
    "                    100, \n",
    "                    weights=[embedding_matrix], \n",
    "                    input_length=seq_length, \n",
    "                    trainable=False))\n",
    "\n",
    "model_2.add(SimpleRNN(rnn_hidden_dim, kernel_initializer=initializers.RandomNormal(stddev=0.001), \n",
    "                      recurrent_initializer=initializers.Identity(gain=1.0), \n",
    "                      activation='relu'))\n",
    "\n",
    "model_2.add(Dense(20, activation='softmax'))\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(lr=0.002)\n",
    "\n",
    "model_2.compile(loss='categorical_crossentropy', \n",
    "              optimizer=rmsprop, \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 2s 7ms/step - loss: 2.8911 - accuracy: 0.1754 - val_loss: 2.8559 - val_accuracy: 0.2410\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 2.3090 - accuracy: 0.3055 - val_loss: 2.1997 - val_accuracy: 0.3328\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 2.1286 - accuracy: 0.3568 - val_loss: 2.2089 - val_accuracy: 0.3286\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 2.0135 - accuracy: 0.3895 - val_loss: 2.1596 - val_accuracy: 0.3428\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.9222 - accuracy: 0.4109 - val_loss: 2.0930 - val_accuracy: 0.3699\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 1.8715 - accuracy: 0.4281 - val_loss: 2.1908 - val_accuracy: 0.3698\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 1.8299 - accuracy: 0.4444 - val_loss: 2.2570 - val_accuracy: 0.3781\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 2s 4ms/step - loss: 1.7819 - accuracy: 0.4552 - val_loss: 2.3063 - val_accuracy: 0.3484\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.7457 - accuracy: 0.4676 - val_loss: 2.2033 - val_accuracy: 0.3822\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.7222 - accuracy: 0.4710 - val_loss: 2.2836 - val_accuracy: 0.3658\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.7310 - accuracy: 0.4849 - val_loss: 2.2309 - val_accuracy: 0.3676\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 2s 7ms/step - loss: 1.6869 - accuracy: 0.4852 - val_loss: 2.2520 - val_accuracy: 0.3757\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.6721 - accuracy: 0.4887 - val_loss: 2.1461 - val_accuracy: 0.3907\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.6402 - accuracy: 0.5015 - val_loss: 2.2630 - val_accuracy: 0.3825\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 2s 7ms/step - loss: 1.6220 - accuracy: 0.5034 - val_loss: 2.3270 - val_accuracy: 0.3889\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.6178 - accuracy: 0.5098 - val_loss: 2.2243 - val_accuracy: 0.3914\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.5899 - accuracy: 0.5193 - val_loss: 2.4072 - val_accuracy: 0.3817\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 2s 7ms/step - loss: 1.6130 - accuracy: 0.5194 - val_loss: 2.4709 - val_accuracy: 0.3599\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.5669 - accuracy: 0.5281 - val_loss: 2.3949 - val_accuracy: 0.3744\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.5770 - accuracy: 0.5267 - val_loss: 2.5135 - val_accuracy: 0.3995\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.7128 - accuracy: 0.5312 - val_loss: 2.4847 - val_accuracy: 0.3822\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.5349 - accuracy: 0.5336 - val_loss: 2.4149 - val_accuracy: 0.4097\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.5433 - accuracy: 0.5340 - val_loss: 2.3841 - val_accuracy: 0.3929\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 2s 7ms/step - loss: 1.5209 - accuracy: 0.5383 - val_loss: 2.4060 - val_accuracy: 0.3736\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.4977 - accuracy: 0.5450 - val_loss: 2.5081 - val_accuracy: 0.3877\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.5227 - accuracy: 0.5484 - val_loss: 2.4048 - val_accuracy: 0.3899\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.5032 - accuracy: 0.5430 - val_loss: 2.8214 - val_accuracy: 0.3887\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.5111 - accuracy: 0.5469 - val_loss: 2.5494 - val_accuracy: 0.3871\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.5157 - accuracy: 0.5507 - val_loss: 2.7876 - val_accuracy: 0.3840\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.4684 - accuracy: 0.5592 - val_loss: 2.4806 - val_accuracy: 0.3857\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.4779 - accuracy: 0.5579 - val_loss: 2.6252 - val_accuracy: 0.3927\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.4567 - accuracy: 0.5582 - val_loss: 2.9574 - val_accuracy: 0.3759\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.4759 - accuracy: 0.5631 - val_loss: 2.7675 - val_accuracy: 0.3805\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.4700 - accuracy: 0.5632 - val_loss: 2.5496 - val_accuracy: 0.3945\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.4400 - accuracy: 0.5615 - val_loss: 2.8952 - val_accuracy: 0.3603\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.5056 - accuracy: 0.5596 - val_loss: 2.6400 - val_accuracy: 0.3890\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.4473 - accuracy: 0.5666 - val_loss: 2.6361 - val_accuracy: 0.3996\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.4443 - accuracy: 0.5678 - val_loss: 2.6998 - val_accuracy: 0.3933\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.4767 - accuracy: 0.5657 - val_loss: 2.8016 - val_accuracy: 0.3870\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.4326 - accuracy: 0.5671 - val_loss: 2.7184 - val_accuracy: 0.3956\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.4398 - accuracy: 0.5720 - val_loss: 2.8180 - val_accuracy: 0.3765\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.5847 - accuracy: 0.5672 - val_loss: 3.4708 - val_accuracy: 0.3613\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 2s 7ms/step - loss: 1.7036 - accuracy: 0.5498 - val_loss: 2.6670 - val_accuracy: 0.3881\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.4735 - accuracy: 0.5666 - val_loss: 2.9522 - val_accuracy: 0.3792\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.4444 - accuracy: 0.5661 - val_loss: 2.8221 - val_accuracy: 0.3678\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.4343 - accuracy: 0.5688 - val_loss: 2.8390 - val_accuracy: 0.3768\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.5518 - accuracy: 0.5686 - val_loss: 2.8485 - val_accuracy: 0.3943\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.4325 - accuracy: 0.5707 - val_loss: 2.8276 - val_accuracy: 0.3822\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.4367 - accuracy: 0.5711 - val_loss: 2.8091 - val_accuracy: 0.3890\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.4267 - accuracy: 0.5751 - val_loss: 5.5448 - val_accuracy: 0.3802\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.4432 - accuracy: 0.5750 - val_loss: 2.9573 - val_accuracy: 0.3833\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.4212 - accuracy: 0.5745 - val_loss: 2.9651 - val_accuracy: 0.3642\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 3s 7ms/step - loss: 1.5032 - accuracy: 0.5712 - val_loss: 2.9789 - val_accuracy: 0.3890\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 2s 7ms/step - loss: 1.4083 - accuracy: 0.5751 - val_loss: 3.2078 - val_accuracy: 0.3927\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 2s 7ms/step - loss: 1.4551 - accuracy: 0.5719 - val_loss: 3.0067 - val_accuracy: 0.3844\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.4225 - accuracy: 0.5733 - val_loss: 2.9272 - val_accuracy: 0.3945\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.4536 - accuracy: 0.5823 - val_loss: 2.9109 - val_accuracy: 0.3963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.3833 - accuracy: 0.5844 - val_loss: 3.0578 - val_accuracy: 0.3918\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.3940 - accuracy: 0.5837 - val_loss: 3.8533 - val_accuracy: 0.3894\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.4357 - accuracy: 0.5760 - val_loss: 3.8640 - val_accuracy: 0.3856\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.3854 - accuracy: 0.5808 - val_loss: 4.9322 - val_accuracy: 0.3958\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.6968 - accuracy: 0.5812 - val_loss: 3.1243 - val_accuracy: 0.3864\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.3848 - accuracy: 0.5814 - val_loss: 3.0609 - val_accuracy: 0.3909\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.4219 - accuracy: 0.5848 - val_loss: 3.1603 - val_accuracy: 0.3893\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.3828 - accuracy: 0.5808 - val_loss: 3.2002 - val_accuracy: 0.3739\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.3787 - accuracy: 0.5862 - val_loss: 3.1342 - val_accuracy: 0.3864\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.4004 - accuracy: 0.5887 - val_loss: 3.1753 - val_accuracy: 0.3879\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 2s 7ms/step - loss: 1.4267 - accuracy: 0.5828 - val_loss: 3.3527 - val_accuracy: 0.3909\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.4278 - accuracy: 0.5827 - val_loss: 3.1707 - val_accuracy: 0.3929\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.3462 - accuracy: 0.5901 - val_loss: 3.2272 - val_accuracy: 0.3894\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 2s 7ms/step - loss: 1.4104 - accuracy: 0.5854 - val_loss: 3.2906 - val_accuracy: 0.3950\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.3917 - accuracy: 0.5878 - val_loss: 3.3453 - val_accuracy: 0.3930\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.6357 - accuracy: 0.5840 - val_loss: 3.3508 - val_accuracy: 0.3911\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 2s 7ms/step - loss: 1.3519 - accuracy: 0.5923 - val_loss: 3.4562 - val_accuracy: 0.3698\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.3804 - accuracy: 0.5924 - val_loss: 3.6905 - val_accuracy: 0.3832\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.3448 - accuracy: 0.5942 - val_loss: 3.3822 - val_accuracy: 0.3850\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 2s 7ms/step - loss: 1.3716 - accuracy: 0.5935 - val_loss: 3.2474 - val_accuracy: 0.3757\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.8363 - accuracy: 0.5915 - val_loss: 3.3350 - val_accuracy: 0.3937\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.6158 - accuracy: 0.5944 - val_loss: 3.2024 - val_accuracy: 0.3906\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 2s 7ms/step - loss: 1.3467 - accuracy: 0.5923 - val_loss: 3.4027 - val_accuracy: 0.3816\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.3508 - accuracy: 0.5952 - val_loss: 3.6851 - val_accuracy: 0.3370\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.3918 - accuracy: 0.5916 - val_loss: 3.4310 - val_accuracy: 0.3828\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 2s 7ms/step - loss: 1.4201 - accuracy: 0.5904 - val_loss: 3.4399 - val_accuracy: 0.3699\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.3699 - accuracy: 0.5924 - val_loss: 3.7556 - val_accuracy: 0.3869\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.3588 - accuracy: 0.5965 - val_loss: 3.5272 - val_accuracy: 0.3788\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 2s 7ms/step - loss: 1.3726 - accuracy: 0.5937 - val_loss: 3.4866 - val_accuracy: 0.3744\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.3558 - accuracy: 0.5895 - val_loss: 3.5400 - val_accuracy: 0.3680\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.4002 - accuracy: 0.5922 - val_loss: 3.6252 - val_accuracy: 0.3794\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.5288 - accuracy: 0.5879 - val_loss: 3.5751 - val_accuracy: 0.3607\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.3985 - accuracy: 0.5856 - val_loss: 6.0750 - val_accuracy: 0.3725\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.3728 - accuracy: 0.5942 - val_loss: 4.0941 - val_accuracy: 0.3812\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.3841 - accuracy: 0.5932 - val_loss: 3.8224 - val_accuracy: 0.3794\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.3809 - accuracy: 0.5906 - val_loss: 3.6913 - val_accuracy: 0.3721\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.3363 - accuracy: 0.5983 - val_loss: 4.1169 - val_accuracy: 0.3752\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.3635 - accuracy: 0.5967 - val_loss: 3.9441 - val_accuracy: 0.3826\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.3761 - accuracy: 0.5985 - val_loss: 3.4747 - val_accuracy: 0.3860\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 1.4002 - accuracy: 0.5970 - val_loss: 4.6153 - val_accuracy: 0.3727\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.5375 - accuracy: 0.5864 - val_loss: 3.6697 - val_accuracy: 0.3809\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.3834 - accuracy: 0.5879 - val_loss: 3.6687 - val_accuracy: 0.3777\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 2s 6ms/step - loss: 1.3643 - accuracy: 0.5956 - val_loss: 3.6872 - val_accuracy: 0.3630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x238db8c9550>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(x_train, y_train, \n",
    "          batch_size=batch_size, \n",
    "          epochs=100, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a neural network with a SimpleRNN instead of an LSTM (with other dimensions and parameters the same). How does the performance compare?\n",
    "\n",
    "While model_2 seems to learn the training data better than our original model.  However, the original mode performs better on the testing data showing it generalizes better to unforseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 100)         13414300  \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 30)                15720     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                620       \n",
      "=================================================================\n",
      "Total params: 13,430,640\n",
      "Trainable params: 16,340\n",
      "Non-trainable params: 13,414,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Embedding(len(word_index) + 1, \n",
    "                    word_dimension,\n",
    "                    trainable=False))\n",
    "\n",
    "model_3.add(LSTM(30, \n",
    "                 dropout=0.2, \n",
    "                 recurrent_dropout=0.2))\n",
    "\n",
    "model_3.add(Dense(20, activation='softmax'))\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(lr=0.002)\n",
    "\n",
    "model_3.compile(loss='categorical_crossentropy', \n",
    "              optimizer=rmsprop, \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "354/354 [==============================] - 7s 20ms/step - loss: 2.9808 - accuracy: 0.0714 - val_loss: 2.9590 - val_accuracy: 0.0834\n",
      "Epoch 2/20\n",
      "354/354 [==============================] - 8s 22ms/step - loss: 2.9188 - accuracy: 0.1023 - val_loss: 2.9201 - val_accuracy: 0.0971\n",
      "Epoch 3/20\n",
      "354/354 [==============================] - 9s 26ms/step - loss: 2.8625 - accuracy: 0.1180 - val_loss: 2.8856 - val_accuracy: 0.1183\n",
      "Epoch 4/20\n",
      "354/354 [==============================] - 9s 26ms/step - loss: 2.8267 - accuracy: 0.1354 - val_loss: 2.8508 - val_accuracy: 0.1240\n",
      "Epoch 5/20\n",
      "354/354 [==============================] - 9s 25ms/step - loss: 2.7955 - accuracy: 0.1486 - val_loss: 2.8326 - val_accuracy: 0.1418\n",
      "Epoch 6/20\n",
      "354/354 [==============================] - 9s 25ms/step - loss: 2.7645 - accuracy: 0.1621 - val_loss: 2.8130 - val_accuracy: 0.1386\n",
      "Epoch 7/20\n",
      "354/354 [==============================] - 9s 26ms/step - loss: 2.7355 - accuracy: 0.1731 - val_loss: 2.8086 - val_accuracy: 0.1443\n",
      "Epoch 8/20\n",
      "354/354 [==============================] - 9s 25ms/step - loss: 2.7138 - accuracy: 0.1830 - val_loss: 2.7837 - val_accuracy: 0.1630\n",
      "Epoch 9/20\n",
      "354/354 [==============================] - 9s 26ms/step - loss: 2.6915 - accuracy: 0.1931 - val_loss: 2.7541 - val_accuracy: 0.1698\n",
      "Epoch 10/20\n",
      "354/354 [==============================] - 10s 28ms/step - loss: 2.6597 - accuracy: 0.2046 - val_loss: 2.7398 - val_accuracy: 0.1759\n",
      "Epoch 11/20\n",
      "354/354 [==============================] - 9s 26ms/step - loss: 2.6394 - accuracy: 0.2100 - val_loss: 2.7361 - val_accuracy: 0.1826\n",
      "Epoch 12/20\n",
      "354/354 [==============================] - 9s 25ms/step - loss: 2.6158 - accuracy: 0.2220 - val_loss: 2.7254 - val_accuracy: 0.1835\n",
      "Epoch 13/20\n",
      "354/354 [==============================] - 9s 26ms/step - loss: 2.5942 - accuracy: 0.2257 - val_loss: 2.7122 - val_accuracy: 0.1851\n",
      "Epoch 14/20\n",
      "354/354 [==============================] - 9s 26ms/step - loss: 2.5734 - accuracy: 0.2314 - val_loss: 2.6985 - val_accuracy: 0.1933\n",
      "Epoch 15/20\n",
      "354/354 [==============================] - 9s 25ms/step - loss: 2.5563 - accuracy: 0.2377 - val_loss: 2.7019 - val_accuracy: 0.1847\n",
      "Epoch 16/20\n",
      "354/354 [==============================] - 9s 27ms/step - loss: 2.5418 - accuracy: 0.2403 - val_loss: 2.6777 - val_accuracy: 0.2074\n",
      "Epoch 17/20\n",
      "354/354 [==============================] - 9s 26ms/step - loss: 2.5269 - accuracy: 0.2467 - val_loss: 2.6612 - val_accuracy: 0.1985\n",
      "Epoch 18/20\n",
      "354/354 [==============================] - 9s 26ms/step - loss: 2.5060 - accuracy: 0.2548 - val_loss: 2.6536 - val_accuracy: 0.2106\n",
      "Epoch 19/20\n",
      "354/354 [==============================] - 9s 27ms/step - loss: 2.4879 - accuracy: 0.2597 - val_loss: 2.6481 - val_accuracy: 0.2148\n",
      "Epoch 20/20\n",
      "354/354 [==============================] - 9s 26ms/step - loss: 2.4700 - accuracy: 0.2671 - val_loss: 2.6730 - val_accuracy: 0.2123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x238dbd754e0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(x_train, y_train, \n",
    "          batch_size=batch_size, \n",
    "          epochs=20, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the LSTM above without the pretrained word vectors (randomly initialize the weights and have them be learned during the training process). How does the performance compare?\n",
    "\n",
    "The accuracies for both training and testing data are significantly lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different sequence lengths, and dimensions for the hidden state of the LSTM. Can you improve the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 50, 100)           13414300  \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                2020      \n",
      "=================================================================\n",
      "Total params: 13,496,720\n",
      "Trainable params: 82,420\n",
      "Non-trainable params: 13,414,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4 = Sequential()\n",
    "model_4.add(Embedding(len(word_index) + 1, \n",
    "                    100, \n",
    "                    weights=[embedding_matrix], \n",
    "                    input_length=50, \n",
    "                    trainable=False))\n",
    "\n",
    "model_4.add(LSTM(100, # 50 \n",
    "                 dropout=0.3, \n",
    "                 recurrent_dropout=0.3))\n",
    "\n",
    "model_4.add(Dense(20, activation='softmax'))\n",
    "\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(lr=0.002)\n",
    "\n",
    "model_4.compile(loss='categorical_crossentropy', \n",
    "              optimizer=rmsprop, \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 50) for input Tensor(\"embedding_5_input:0\", shape=(None, 50), dtype=float32), but it was called on an input with incompatible shape (None, 30).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 50) for input Tensor(\"embedding_5_input:0\", shape=(None, 50), dtype=float32), but it was called on an input with incompatible shape (None, 30).\n",
      "354/354 [==============================] - ETA: 0s - loss: 2.5567 - accuracy: 0.2021WARNING:tensorflow:Model was constructed with shape (None, 50) for input Tensor(\"embedding_5_input:0\", shape=(None, 50), dtype=float32), but it was called on an input with incompatible shape (None, 30).\n",
      "354/354 [==============================] - 10s 29ms/step - loss: 2.5567 - accuracy: 0.2021 - val_loss: 2.2258 - val_accuracy: 0.2921\n",
      "Epoch 2/20\n",
      "354/354 [==============================] - 12s 35ms/step - loss: 2.0785 - accuracy: 0.3541 - val_loss: 2.0825 - val_accuracy: 0.3522\n",
      "Epoch 3/20\n",
      "354/354 [==============================] - 12s 35ms/step - loss: 1.8314 - accuracy: 0.4317 - val_loss: 1.8374 - val_accuracy: 0.4331\n",
      "Epoch 4/20\n",
      "354/354 [==============================] - 12s 35ms/step - loss: 1.6645 - accuracy: 0.4842 - val_loss: 1.7980 - val_accuracy: 0.4546\n",
      "Epoch 5/20\n",
      "354/354 [==============================] - 12s 35ms/step - loss: 1.5464 - accuracy: 0.5202 - val_loss: 1.7525 - val_accuracy: 0.4744\n",
      "Epoch 6/20\n",
      "354/354 [==============================] - 12s 35ms/step - loss: 1.4479 - accuracy: 0.5535 - val_loss: 1.7581 - val_accuracy: 0.4790\n",
      "Epoch 7/20\n",
      "354/354 [==============================] - 12s 34ms/step - loss: 1.3692 - accuracy: 0.5816 - val_loss: 1.7336 - val_accuracy: 0.4869\n",
      "Epoch 8/20\n",
      "354/354 [==============================] - 14s 40ms/step - loss: 1.2915 - accuracy: 0.5971 - val_loss: 1.7182 - val_accuracy: 0.5001\n",
      "Epoch 9/20\n",
      "354/354 [==============================] - 18s 51ms/step - loss: 1.2535 - accuracy: 0.6143 - val_loss: 1.7571 - val_accuracy: 0.5017\n",
      "Epoch 10/20\n",
      "354/354 [==============================] - 14s 40ms/step - loss: 1.1921 - accuracy: 0.6319 - val_loss: 1.7361 - val_accuracy: 0.5121\n",
      "Epoch 11/20\n",
      "354/354 [==============================] - 14s 39ms/step - loss: 1.1592 - accuracy: 0.6472 - val_loss: 1.7219 - val_accuracy: 0.5127\n",
      "Epoch 12/20\n",
      "354/354 [==============================] - 13s 36ms/step - loss: 1.1170 - accuracy: 0.6582 - val_loss: 1.7373 - val_accuracy: 0.5100\n",
      "Epoch 13/20\n",
      "354/354 [==============================] - 13s 36ms/step - loss: 1.0618 - accuracy: 0.6751 - val_loss: 1.7660 - val_accuracy: 0.5150\n",
      "Epoch 14/20\n",
      "354/354 [==============================] - 18s 51ms/step - loss: 1.0520 - accuracy: 0.6726 - val_loss: 1.7477 - val_accuracy: 0.5150\n",
      "Epoch 15/20\n",
      "354/354 [==============================] - 14s 39ms/step - loss: 1.0228 - accuracy: 0.6816 - val_loss: 1.7979 - val_accuracy: 0.5151\n",
      "Epoch 16/20\n",
      "354/354 [==============================] - 15s 43ms/step - loss: 0.9954 - accuracy: 0.6849 - val_loss: 1.7731 - val_accuracy: 0.5218\n",
      "Epoch 17/20\n",
      "354/354 [==============================] - 14s 39ms/step - loss: 0.9705 - accuracy: 0.6944 - val_loss: 1.8040 - val_accuracy: 0.5174\n",
      "Epoch 18/20\n",
      "354/354 [==============================] - 13s 37ms/step - loss: 0.9557 - accuracy: 0.6968 - val_loss: 1.8095 - val_accuracy: 0.5232\n",
      "Epoch 19/20\n",
      "354/354 [==============================] - 14s 39ms/step - loss: 0.9269 - accuracy: 0.7104 - val_loss: 1.8076 - val_accuracy: 0.5251\n",
      "Epoch 20/20\n",
      "354/354 [==============================] - 13s 37ms/step - loss: 0.9150 - accuracy: 0.7136 - val_loss: 1.8427 - val_accuracy: 0.5206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ff40b1b1d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.fit(x_train, y_train, \n",
    "          batch_size=batch_size, \n",
    "          epochs=20, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By increase the our sequence length to 50 and building 100 hidden layers we have a model that in theory is better than a random guess, unlike the other models.  However, when comparing the training data accuracy with validation data we can see a strong indicator of overfitting the training set in our model.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Neural Networks\n",
    "\n",
    "## Exercise: neurons as logic gates\n",
    "In this exercise we will experiment with neuron computations.  We will show how to represent basic logic functions like AND, OR, and XOR using single neurons (or more complicated structures).  Finally, at the end we will walk through how to represent neural networks as a chain of matrix computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid function:\n",
    "\n",
    "$$\n",
    "\\sigma = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "$\\sigma$ ranges from (0, 1). When the input $x$ is negative, $\\sigma$ is close to 0. When $x$ is positive, $\\sigma$ is close to 1. At $x=0$, $\\sigma=0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.12717101690833e+64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Quickly define the sigmoid function\n",
    "math.exp(-1 * -149)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16459a13898>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "x =  np.arange(-10., 10., 0.2)\n",
    "y = [sigmoid(i) for i in x]\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking of neurons as boolean logic gates\n",
    "\n",
    "A logic gate takes in two boolean (true/false or 1/0) inputs, and returns either a 0 or 1 depending on its rule. The truth table for a logic gate shows the outputs for each combination of inputs, (0, 0), (0, 1), (1,0), and (1, 1). For example, let's look at the truth table for an \"OR\" gate:\n",
    "\n",
    "### OR Gate\n",
    "\n",
    "<table>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"3\">OR gate truth table</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"2\">Input</th>\n",
    "<th>Output</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "A neuron that uses the sigmoid activation function outputs a value between (0, 1). This naturally leads us to think about boolean values. Imagine a neuron that takes in two inputs, $x_1$ and $x_2$, and a bias term:\n",
    "\n",
    "![](images/logic01.png)\n",
    "\n",
    "By limiting the inputs of $x_1$ and $x_2$ to be in $\\left\\{0, 1\\right\\}$, we can simulate the effect of logic gates with our neuron. The goal is to find the weights (represented by ? marks above), such that it returns an output close to 0 or 1 depending on the inputs.\n",
    "\n",
    "What numbers for the weights would we need to fill in for this gate to output OR logic? Observe from the plot above that $\\sigma(z)$ is close to 0 when $z$ is largely negative (around -10 or less), and is close to 1 when $z$ is largely positive (around +10 or greater).\n",
    "\n",
    "$$\n",
    "z = w_1 x_1 + w_2 x_2 + b\n",
    "$$\n",
    "\n",
    "Let's think this through:\n",
    "\n",
    "* When $x_1$ and $x_2$ are both 0, the only value affecting $z$ is $b$. Because we want the result for (0, 0) to be close to zero, $b$ should be negative (at least -10)\n",
    "* If either $x_1$ or $x_2$ is 1, we want the output to be close to 1. That means the weights associated with $x_1$ and $x_2$ should be enough to offset $b$ to the point of causing $z$ to be at least 10.\n",
    "* Let's give $b$ a value of -10. How big do we need $w_1$ and $w_2$ to be? \n",
    "    * At least +20\n",
    "* So let's try out $w_1=20$, $w_2=20$, and $b=-10$!\n",
    "\n",
    "![](images/logic02.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: [0, 0] => output: 0\n",
      "input: [0, 1] => output: 1\n",
      "input: [1, 0] => output: 1\n",
      "input: [1, 1] => output: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "def or_gate(x):\n",
    "    w = [2, 2] #[.55, .55]\n",
    "    b = -1 # -.05\n",
    "    res = (w[0] * x[0]) + (w[1] * x[1]) + b\n",
    "    return  0 if res <= 0 else 1\n",
    "\n",
    "for i in inputs:\n",
    "    print('input: {} => output: {}'.format(i, or_gate(i)))\n",
    "    \n",
    "or_gate([.35, .35])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"3\">OR gate truth table</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"2\">Input</th>\n",
    "<th>Output</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "This matches! Great! Now you try finding the appropriate weight values for each truth table. Try not to guess and check- think through it logically and try to derive values that work.\n",
    "\n",
    "### AND Gate\n",
    "\n",
    "<table>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"3\">AND gate truth table</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"2\">Input</th>\n",
    "<th>Output</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Try to figure out what values for the neurons would make this function as an AND gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: [0, 0] => output: 0\n",
      "input: [0, 1] => output: 0\n",
      "input: [1, 0] => output: 0\n",
      "input: [1, 1] => output: 1\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Fill in the w1, w2, and b parameters such that the truth table matches\n",
    "inputs = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "def and_gate(x):\n",
    "    w = [1, 1]\n",
    "    b = -1\n",
    "    res = (w[0] * x[0]) + (w[1] * x[1]) + b\n",
    "    return 0 if res <= 0 else 1\n",
    "\n",
    "for i in inputs:\n",
    "    print('input: {} => output: {}'.format(i, and_gate(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Do the same for the NOR gate and the NAND gate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOR (Not Or) Gate\n",
    "\n",
    "<table>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"3\">NOR gate truth table</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"2\">Input</th>\n",
    "<th>Output</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: [0, 0] => output: 1\n",
      "input: [0, 1] => output: 0\n",
      "input: [1, 0] => output: 0\n",
      "input: [1, 1] => output: 0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Fill in the w1, w2, and b parameters such that the truth table matches\n",
    "inputs = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "def nor_gate(x):\n",
    "    w = [-1, -1]\n",
    "    b = 1\n",
    "    res = (w[0] * x[0]) + (w[1] * x[1]) + b\n",
    "    return  0 if res <= 0 else 1\n",
    "\n",
    "for i in inputs:\n",
    "    print('input: {} => output: {}'.format(i, nor_gate(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAND (Not And) Gate\n",
    "\n",
    "<table>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"3\">NAND gate truth table</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"2\">Input</th>\n",
    "<th>Output</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: [0, 0] => output: 1\n",
      "input: [0, 1] => output: 1\n",
      "input: [1, 0] => output: 1\n",
      "input: [1, 1] => output: 0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Fill in the w1, w2, and b parameters such that the truth table matches\n",
    "# TO DO: Fill in the w1, w2, and b parameters such that the truth table matches\n",
    "inputs = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "def nand_gate(x):\n",
    "    w = [-1, -1]\n",
    "    b = 2\n",
    "    res = (w[0] * x[0]) + (w[1] * x[1]) + b\n",
    "    return  0 if res <= 0 else 1\n",
    "\n",
    "for i in inputs:\n",
    "    print('input: {} => output: {}'.format(i, nand_gate(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The limits of single neurons\n",
    "\n",
    "If you've taken computer science courses, you may know that the XOR gates are the basis of computation. They can be used as so-called \"half-adders\", the foundation of being able to add numbers together. Here's the truth table for XOR:\n",
    "\n",
    "### XOR (Exclusive Or) Gate\n",
    "\n",
    "<table>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"3\">XOR gate truth table</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"2\">Input</th>\n",
    "<th>Output</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "Now the question is, can you create a set of weights such that a single neuron can output this property?\n",
    "\n",
    "It turns out that you cannot. Single neurons can't correlate inputs, so it's just confused. So individual neurons are out. Can we still use neurons to somehow form an XOR gate?\n",
    "\n",
    "What if we tried something more complex:\n",
    "\n",
    "![](images/logic03.png)\n",
    "\n",
    "Here, we've got the inputs going to two separate gates: the top neuron is an OR gate, and the bottom is a NAND gate. The output of these gates then get passed to another neuron, which is an AND gate. If you work out the outputs at each combination of input values, you'll see that this is an XOR gate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: [0, 0] => output: 0\n",
      "input: [0, 1] => output: 1\n",
      "input: [1, 0] => output: 1\n",
      "input: [1, 1] => output: 0\n"
     ]
    }
   ],
   "source": [
    "# Make sure you have or_gate, nand_gate, and and_gate working from above!\n",
    "inputs = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "\n",
    "def xor_gate(x):\n",
    "    or_res = or_gate(x)\n",
    "    nand_res = nand_gate(x)\n",
    "    \n",
    "    res = and_gate([or_res, nand_res])\n",
    "    return  0 if res <= 0 else 1\n",
    "\n",
    "for i in inputs:\n",
    "    print('input: {} => output: {}'.format(i, xor_gate(i))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward Networks as Matrix Computations\n",
    "\n",
    "We discussed previously how the feed-forward computation of a neural network can be thought of as matrix calculations and activation functions.  We will do some actual computations with matrices to see this in action.\n",
    "\n",
    "![](images/FF_NN.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Provided below are the following:\n",
    "\n",
    "- Three weight matrices `W_1`, `W_2` and `W_3` representing the weights in each layer.  The convention for these matrices is that each $W_{i,j}$ gives the weight from neuron $i$ in the previous (left) layer to neuron $j$ in the next (right) layer.  \n",
    "- A vector `x_in` representing a single input and a matrix `x_mat_in` representing 7 different inputs.\n",
    "- Two functions: `soft_max_vec` and `soft_max_mat` which apply the soft_max function to a single vector, and row-wise to a matrix.\n",
    "\n",
    "The goals for this exercise are:\n",
    "1. For input `x_in` calculate the inputs and outputs to each layer (assuming sigmoid activations for the middle two layers and soft_max output for the final layer.\n",
    "2. Write a function that does the entire neural network calculation for a single input\n",
    "3. Write a function that does the entire neural network calculation for a matrix of inputs, where each row is a single input.\n",
    "4. Test your functions on `x_in` and `x_mat_in`.\n",
    "\n",
    "This illustrates what happens in a NN during one single forward pass. Roughly speaking, after this forward pass, it remains to compare the output of the network to the known truth values, compute the gradient of the loss function and adjust the weight matrices `W_1`, `W_2` and `W_3` accordingly, and iterate. Hopefully this process will result in better weight matrices and our loss will be smaller afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Student to do the calculations below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "calculate each nodes' output for a given layer\n",
    "assumptions:\n",
    "    1) W matrix in format of each row is a different node\n",
    "    2) bias value isn't included in input (x) vector\n",
    "    \n",
    "'''\n",
    "def calculate_layer_outputs(x, W, b):\n",
    "    # vectorize value for each node\n",
    "    x_ = np.append(x, b)\n",
    "    W_ = np.hstack((W, np.ones((W.shape[0], 1))))\n",
    "    A = W_.dot(x_)\n",
    "    Z = np.vectorize(sigmoid)(A)\n",
    "    return Z\n",
    "\n",
    "\n",
    "'''\n",
    "calculate neural network's output by going through each layer\n",
    "using same assumptions as above\n",
    "inputs:\n",
    "    x: input into neural network\n",
    "    W_mat is 3d array of NN's layer weights where \n",
    "        W_mat[i] is layer i's weights\n",
    "        W_mat[i, j] is node j in layer i weights\n",
    "        W_mat[i, j, k] is the kth weight in node j of layer i\n",
    "    B: vector of each layers' bias values\n",
    "'''\n",
    "def calculate_nn_output(x, W_mat, B):\n",
    "    layer_inputs = [x]\n",
    "    layer_outputs = []\n",
    "    for layer_i in range(W_mat.shape[0]):\n",
    "        W = W_mat[layer_i]\n",
    "        b = B[layer_i]\n",
    "        \n",
    "        Z = calculate_layer_outputs(layer_inputs[-1], W, b)\n",
    "        layer_outputs.append(Z)\n",
    "        layer_inputs.append(layer_outputs[-1])\n",
    "        \n",
    "    retuen return layer_inputs, layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_inputs: [array([0.05, 0.1 ]), array([0.59326999, 0.59688438])]\n",
      "layer_outputs: [array([0.59326999, 0.59688438]), array([0.75136507, 0.77292847])]\n"
     ]
    }
   ],
   "source": [
    "## A one-line function to do the entire neural net computation\n",
    "W_1 = np.array([[.15, .20], [.25, .30]])\n",
    "W_2 = np.array([[.40, .45], [.50, .55]])\n",
    "W_mat = np.array([W_1, W_2])\n",
    "Bias = np.array([.35, .60])\n",
    "x = np.array([.05, .10])\n",
    "\n",
    "\n",
    "layer_inputs, layer_outputs = calculate_nn_output(x, W_mat, Bias)\n",
    "print('layer_inputs: {}'.format(layer_inputs[0:-1]))\n",
    "print('layer_outputs: {}'.format(layer_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.75136507, 0.77292847]),\n",
       " array([0.75480674, 0.77690552]),\n",
       " array([0.75974269, 0.78259254]),\n",
       " array([0.76289415, 0.78620639])]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "assuming each row in X_mat is a new input then apply \n",
    "calculate_nn_output on each row in matrix and only store\n",
    "the last element in the second array returned to get the \n",
    "network's output\n",
    "'''\n",
    "X = np.array([[.05, .10], [.50, .10], [.05, 1.0], [.50, 1.0]])\n",
    "y = [  calculate_nn_output(x, W_mat, Bias)[1][-1]  for x in X]\n",
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
